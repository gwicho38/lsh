{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to lpy-bqklOfEz-py3.12 (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 15:16:00.732863: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-16 15:16:00.733031: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 15:16:00.735005: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 15:16:00.759154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 15:16:01.276892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import click\n",
    "import os\n",
    "import subprocess\n",
    "import signal\n",
    "from typing import Any\n",
    "from keras.api.models import load_model\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.src.layers.core.dense import Dense\n",
    "from keras.api.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lefv/.cache/pypoetry/virtualenvs/lpy-bqklOfEz-py3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '4' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m create_model(\u001b[39m4\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model\u001b[39m(input_shape):\n\u001b[0;32m----> 2\u001b[0m     model \u001b[39m=\u001b[39m Sequential([\n\u001b[1;32m      3\u001b[0m         Dense(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49minput_shape),\n\u001b[1;32m      4\u001b[0m         Dense(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m         Dense(\u001b[39m3\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m     ])\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lpy-bqklOfEz-py3.12/lib/python3.12/site-packages/keras/src/models/sequential.py:73\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m layers:\n\u001b[1;32m     72\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[0;32m---> 73\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(layer, rebuild\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_rebuild()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lpy-bqklOfEz-py3.12/lib/python3.12/site-packages/keras/src/models/sequential.py:86\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layers:\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(layer, \u001b[39m\"\u001b[39m\u001b[39m_input_shape_arg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(InputLayer(shape\u001b[39m=\u001b[39;49mlayer\u001b[39m.\u001b[39;49m_input_shape_arg))\n\u001b[1;32m     88\u001b[0m \u001b[39m# If we are passed a Keras tensor created by keras.Input(), we\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# extract the input layer from its keras history and use that.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(layer, \u001b[39m\"\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lpy-bqklOfEz-py3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:46\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[0;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, name, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must pass a `shape` argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     shape \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mstandardize_shape(shape)\n\u001b[1;32m     47\u001b[0m     batch_shape \u001b[39m=\u001b[39m (batch_size,) \u001b[39m+\u001b[39m shape\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(batch_shape)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lpy-bqklOfEz-py3.12/lib/python3.12/site-packages/keras/src/backend/common/variables.py:530\u001b[0m, in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUndefined shapes are not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(shape, \u001b[39m\"\u001b[39m\u001b[39m__iter__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 530\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot convert \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to a shape.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mbackend() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(shape, tf\u001b[39m.\u001b[39mTensorShape):\n\u001b[1;32m    533\u001b[0m         \u001b[39m# `tf.TensorShape` may contain `Dimension` objects.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m         \u001b[39m# We need to convert the items in it to either int or `None`\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert '4' to a shape."
     ]
    }
   ],
   "source": [
    "model = create_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model((4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_checkpoint_1518.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_checkpoint_1518.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpy-bqklOfEz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
